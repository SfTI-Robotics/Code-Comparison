# DQN Code comparison 

Code used:

### Mountain Car

Yash (medium): [Article](https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c)|[Code](https://gist.github.com/yashpatel5400/049fe6f4372b16bab5d3dab36854f262)

Adam

cnblogs: [Article + code](https://www.cnblogs.com/wangxiaocvpr/p/5995336.html)

### Retro

Free code camp: [Article](https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8)|[Code](https://gist.github.com/simoninithomas/7611db5d8a6f3edde269e18b97fa4d0c#file-deep-q-learning-with-doom-ipynb)

### Cart Pole

Greg (medium): [Article](https://towardsdatascience.com/cartpole-introduction-to-reinforcement-learning-ed0eb5b58288)|[Code](https://github.com/gsurma/cartpole)

Matt (medium): [Article](https://medium.com/@tuzzer/follow-up-cart-pole-balancing-with-q-network-976d13f88d2f)|[Code](https://github.com/MattChanTK/ai-gym/blob/master/cart_pole/cart_pole_dqn_cntk.py)

Omar : [Code](https://github.com/OmarAflak/CartPole-DQN/blob/master/dqn.py)

### Frozen lake 
[Code](https://gist.github.com/awjuliani/9024166ca08c489a60994e529484f7fe#file-q-table-learning-clean-ipynb)
